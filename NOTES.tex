\documentclass{report}

\input{preamble}
\input{macros}
\input{letterfonts}

\title{\Huge{Advanced Statistical Mechanics}\\Part III Physics, Unversity of Cambridge}
\author{\huge{Lawrence Wu}}
\date{\today}

\begin{document}

\maketitle
\newpage% or \cleardoublepage
% \pdfbookmark[<level>]{<title>}{<dest>}
\pdfbookmark[section]{\contentsname}{toc}
\tableofcontents
\pagebreak
%
%=======================================
%Lecture 1
%=======================================
%
\chapter{Lecture 1: Revision of equilibrium stochastic physics}
\section{Prerequisite: Canonical coordinates and Phase space}
In mathematics and classical mechanics, canonical coordinates are sets of coordinates on phase space which can be used to describe a physical system at any given point in time. In dynamical system theory, a phase space is a space in which all possible states of a system are represented, with each possible state corresponding to one unique point in the phase space.
\section{Micro-canonical ensemble}
In statistical mechanics, the microcanonical ensemble is a statistical ensemble that represents the possible states of a mechanical system whose total energy is exactly specified. The system is assumed to be isolated in the sense that it cannot exchange energy or particles with its environment, so that (by conservation of energy) the energy of the system does not change with time. In the Micro-canonical ensemble, the Hamiltonian for the system is usually defined as a function of the canonical coordinates momentum $\bmp$ and position $\bmq$:
\begin{align}
    \SH = \SH (\bmp, \bmq)
\end{align}
which allows the different states of the system to be represented in phase space $\PP$ and $\QQ$. The energy of system E would be the weighted mean of $\SH$ in phase space. Rather than solving for the behaviour of a particular set of initial conditions, let us hypothesise that the energy is all we need to describe the equilibrium state. This leads us to a statistical mechanical description of the equilibrium state of our system as an ensemble of all possible states with energy Eâ€”the microcanonical ensemble.
Now consider the scenario where, for a given E, we introduce a small positive change dE in energy and the volume of the allowed states in phase space is changed. We define:
\begin{align}
    \Omega(E)\ dE & = \intphase \quad (\text{for states with } E <  \ham < E + dE)                             \\
                  & =\intphase \Theta(E+dE-H)-\Theta(E-H) \quad (\Theta\text{ is the Heaviside step function}) \\
                  & =d E \cdot \intphase \left[\frac{\partial\Theta(\E-H)}{\partial E}\right]                        \\
\end{align}
and we reach the conclusion:
\dfn{Number of states with hamiltonian $\SH$ equal to given energy E.}{$$\Rightarrow \Omega(E) = \intphase \delta(E - \ham$$)}
\noindent We then define the "entropy" S to be:
\dfn{Entropy}{$$\bmS(E) = k_B \ln \Omega(E)$$}
Now let's talk about probability $\rho(E)$. But how do we define it and how is it useful? Let's consider a quantity of the system $X(\bmp, \bmq)$ and we're trying to deduce its expectation value $\langle X \rangle$. We'll want to integrate over all states with the constraint $\SH = E$:
\begin{align}
    \langle X(\bmp, \bmq) \rangle & = \frac{1}{\Omega(E)}\intphase X(\bmp, \bmq) \delta(E - \ham)
\end{align}
where we can read out the normalised probability $\rho(E)$ to be:
\dfn{Normalised probability}{$$\rho(E) = \frac{1}{\Omega(E)}\delta(E - \ham)$$}
\noindent There is a useful spooky relation when it comes to relating $\Omega$s for different energies:
\qs{}{Check that for a system consisting of two subsystems with total energy E:$$\Omega(E)=\int \Omega_1\left(E_1\right) \Omega_2\left(E-E_1\right) d E_1$$ as should be intuitively clear}
\section{Canonical ensemble}
In comparison with the micro-canonical ensemble, a canonical ensemble is a statistical ensemble that represents the possible states of a mechanical system in thermal equilibrium with a heat bath at a fixed temperature. The system can exchange energy with the heat bath so that the states of the system will differ in total energy. Since the energy is not fixed, we assign a probability P to each distinct state that's related to their energy:
\begin{align}
    P \propto e^{-\beta E}
\end{align}
\noindent and for P to be normalised, we define the normalisation factor Z aka the partition function to be:
\dfn{The partition function}{
    \begin{align}
        Z & = \sum_{All\ states} e^{-\beta E} = \intphase e^{\beta -\ham} \\
          & = \sum_{Microstates(E)} \Omega(E) e^{-\beta E}               \\
          & = \sum_{Microstates(E)} e^{-\beta (E-k_B T \ln \Omega(E))}   \\
    \end{align}
}
\noindent Where we often call the value in the exponent the "Free energy" of a microstate.
\dfn{Free energy}{$$F(E) = E - TS(E)$$}
\noindent After normalisation, our normalised probability becomes:
\dfn{Probabilty for the system to have energy E}{$$\rho(E) = \frac{1}{Z} e^{\beta(E-TS)}$$}
\noindent From the relation above, we can see that the probability is maximised when the free energy F is minimised. And for a large system, this gives the equilibrium state due to the central limit theorem. (We will go further into this in the later lectures.)

In conclusion, minimising the free energy allow us to find the balance between the two incompatible demands in statistical physics: 1. Minimising energy E 2. Maximising entropy S(E), and ignoring the fluctuation in the system about this preferred microstate. But in this course, we aim to look at two non-equilibrium questions: 1. How long does it take to reach such an equilibrium state from an initial state? 2. Are there barriers and metastabilities states?
\section{Different types of systems (Hohenberg-Halperin 1977)}
\subsection{Model A: No conservation laws}
An order parameter $\phi$ is defined to be a variable that can be used to describe a system and gives a complete description of the hamiltonian. In other words, the Hamiltonian can be written in the form $\SH(\phi)$. And when there are no conservation laws in a system for this parameter $\phi$, we call it a Model A system. For example, the magnetisation of a magnetic system is an order parameter of Model A since it does not have to be conserved at all. For models like this we can make a classical mechanical analogy (Think of $\phi$ as the cartesian coordinates of a particle):
\begin{align}
    \text{"driving force"}                    & = \text{"friction force"}                 \\
    -\frac{\partial \SH(\phi)}{\partial \phi} & = \gamma \frac{\partial \phi}{\partial t}
\end{align}
\noindent And this will be the principal which controls the evolution of the system towards equilibrium. This is in contrast with another type of system that we call Model B:
\subsection{Model B: Conserved fields}
For this type of system, we have a conservation law of the form:
\begin{align}
    \int \phi(\bmx) d\bmx = constant
\end{align}
\noindent and for this type of system, since we can only change the distribution of this parameter but not the total quantity, the characteristic equation will be the classical continuity equation:
\begin{align}
    \del{\phi}{t} = -D \nabla^2 \del{\SH(\phi)}{\phi}
    \intertext{where the flux J is:}
    \bmJ = -D \nabla \del{\SH}{\phi}
\end{align}
\subsection{Model C-F...}
Model C describes a field $\phi$ that is coupled to a conserved auxiliary field and such analysis goes down all the way to Model F. There's no need to know all of them and the above sections are just raising awareness that these mechanical analysis exists.

%
%=======================================
%Lecture 2
%=======================================
%
\chapter{Lecture 2: Basic definitions of probability theory}
\section{Random Variables and Probabilty}

As the title suggests, this lecture covers the basic of probability theory so there is a common language that we can use to describe stochastic systems. Let's start with the definition of "Random variables" or "Stochastic variables". A random variable $x$ with a microscopic probability $P(x)$ has the definitions:
\dfn{EV and Variance}{
    \begin{align}
        \text{Expectation value:}& \ \langle x \rangle=\int x \cdot P(x) dx\\
        \text{Variance:}& \ \ \sigma^2 = \langle x^2 \rangle - \langle x \rangle^2
    \end{align}
}
\noindent We then introduce the concept of characteristic functions $\phi_x(k)$ that most of you probably have not seen before, which is the expectation value of $e^{ikx}$:
\dfn{Characteristic function}{
    \begin{align}
        \phi_x(k) = \langle e^{ikx}\rangle_{P(x)} = \int e^{ikx} P(x) dx
    \end{align}
}
\noindent where we can see is just simply the Fourier Transform of $P(x)$! But if we expand the exponential in terms of the Taylor series:
\begin{align}
    \phi_x(k) &= \int e^{ikx} P(x) dx\\
    &= \int \sum_{n=0}^{\infty} \frac{1}{n!} (ikx)^n P(x) dx\\
    &= \sum_{n=0}^{\infty} \frac{(ik)^n}{n!} \langle x^n \rangle\\
\end{align}
\noindent where we call $\langle x^n \rangle$ the $n^{th}$ moment of the probability $P(X)$. 
\dfn{Moments of P(x)}{
    \begin{align}
        n^{th} \ moment: \langle x^n \rangle = \int x^n P(x) dx
    \end{align}
}
\noindent We can also express the characteristic equation in terms of an exponential of a sum:
\begin{align}
    \phi_x(k)=\exp \left[\sum_{n=0}^{\infty} \frac{(i k)^n}{n !} C_n\right]
\end{align}
\noindent where we call the coefficient $C_n$ the cumulants of P(x) and we can calculate them directly from a probability distribution $P(x)$:
\dfn{Cumulants}{
    \begin{align}
        C_n = \frac{d^n}{d(i k)^n} \ln \phi_x(k)\ |_{k=0}
    \end{align}
}
\ex{$C_1$}{
    \begin{align}
        C_1&=\frac{d}{d\left(ik\right)} \ln \left(\sum_{n=0}^{\infty} \frac{(i k)^n}{n !}\left\langle x^n\right\rangle\right)_{k=0}\\
        &=\left[\frac{1}{i} \frac{i \sum_m \frac{1}{(m-1)!}(i k)^{m-1}\left\langle x^m\right\rangle}{\sum_n(i k)^n / m !\left\langle x^n\right\rangle}\right]_{k=0}\\
        &= \langle x \rangle
    \end{align}
}
\qs{$C_2$}{Check that $C_2 = \sigma^2 = \langle x^2 \rangle - \langle x \rangle^2$}
\noindent due to the Fourier transform nature of the characteristic function, we can see that if $P(x)$ is a Gaussian, then so is $\phi_x(k)$:
\begin{align}
    P = exp\left(-\frac{\left(x-x_0\right)^2}{2\sigma^2}\right) \Leftrightarrow \phi_x(k) = e\left(-\frac{\sigma^2 k^2}{2}+i k x_0\right)
\end{align}
\section{Random Walk} \label{section:random_walk}
Let's now consider a linked sequence $y_N$ of random variables $x_i$ with identical probability distributions $P(x)$ (For example the length of a polymer chain with N identical links randomly folded), we call this a "random walk" or a "stochastic process":
\dfn{Random walk}{
    \begin{align}
        y_N = \sum_{i=1}^{N}x_i\\
        \left\langle y_N\right\rangle=N\langle x\rangle\\
        \sigma_y^2 = \left\langle y_N^2\right\rangle-\langle y_N\rangle^2 = N \sigma^2 \label{eq:random_walk_variance}\\
    \end{align}
}
where the variance relationship came from:
\begin{align}
\left\langle y^2\right\rangle-\langle y\rangle^2&=\sum_i \sum_j\left\langle x_i x_j\right\rangle-\sum_i\left\langle x_i\right\rangle \sum_j\left\langle x_j\right\rangle \\
&=N\left\langle x^2\right\rangle+N(N-1)\langle x\rangle^2-N^2\langle x\rangle^2 \\
&=N\left(\left\langle x^2\right\rangle-\langle x)^2\right)=N \sigma^2
\end{align}
Now we introduce the normalised random walk $S_N = y_N/N$ where $\ev{S_N} = \ev{x_N}$ and $\sigma_S^2 = \sigma_x^2/N$, and the central limit theorem suggests that no matter what $P(x)$ is, $P(S_N)$ will always converge to a Gaussian:
\thm{Central Limit theorem}{
    For a normalised random walk $S_N$ where:
    \begin{align}
        S_N &= \frac{y_N}{N}\\
        \ev{S_N} &= \ev{x}\\
        \sigma_S^2 &= \frac{\sigma_x^2}{N}\\
    \end{align}
    The probability distribution for $S_N$: $P(S)$ converges to a Gaussian with the same EV and Variance for large N.
}
\begin{myproof} (This is a very rough proof)\\
    We start with the characteristic function $\phi_S(k)$:
    \begin{align}
        \phi_s(k)&=\left\langle e^{i k s}\right\rangle=\left\langle exp\left(i \frac{k}{N} \sum_m x_m\right)\right\rangle \\
        &=\left\langle e^{\frac{i k}{N} x}\right\rangle_{P(x)}^N = \left[\phi_x(\frac{k}{N})\right]^N
    \end{align}
    On the other hand, we can also express $\phi_S(k)$ and $\phi_x(k)$ as:
    \begin{align}
        \phi_s(k) & =\exp \left[\sum_{m=0}^{\infty} \frac{\left({i k}\right)^m}{m !} C_m(s)\right] \\
        & =\left[\phi_x(k / N)\right]^N \\
        & =\left[\exp \left(\sum_{m=0}^N \frac{\left({i k}\right)^m}{m!N^m} C_m(x)\right)\right]^N \\
        & =\exp \left(\sum_{m=0}^N \frac{(i k)^m}{m ! N^{m-1}} C_m(x)\right)
    \end{align}
    From here, it is not hard to convince yourself that as N increases the terms in the sum with $m>1$ will slowly disappear. So if we consider only the first two terms in the sum:
    \begin{align}
        \phi_S(k) &\approx \exp \left(N+i k C_1(x)-\frac{k^2}{2 N} C_2(x)\right)\\
        &= \exp \left(N+i k \ev{x} - \frac{k^2}{2 N} \sigma_x^2\right)
    \end{align}
    This is just the Fourier Transform of a Gaussian with the mean and variance mentioned above! Therefore, FTing it back to $P(S)$ gives us our desired result.
\end{myproof}
\section{Random walk in time}
If we replace N in the random walk with time t, we reach a stochastic process $y(t)$ where we're randomly drifting around over continuous time. In this section, we go through a few key properties of this stochastic process.
\subsection{probabilities}
We can then define a set of probabilities:
\dfn{Probabilities for random walks in time}{
    \begin{align}
        P_1(y,t)&: the\ probability\ of\ being\ at\ value\ y\ at\ time\ t\\
        P_2(y_1, y_2| t_1, t_2)&: probability\ of\ being\ at\ (y_1,t_1)\ and\ then\ (y_2,t_2)\\
        \vdots & \ \ and\ so\ on
    \end{align}
}
\subsection{Normalisation}
These probabilities are normalised by:
\begin{align}
    1&=\int d y_1 \ldots d y_N \ P_N\left(y_1, y_2 \ldots y_N \mid t_1, t_2 \ldots t_N\right)\\
\end{align}
which is saying if we consider all possible $y_i$ at the given times $t=t_i$, we should have a total probability of 1.
\ex{}{
    \begin{align}
        1&=\int d y P_1(y, t)
    \end{align}
}
\subsection{Reduction}
\thm{Reduction}{
    The probability $P_N$ can be reduced into $P_{N-1}$ by reduction:
    \begin{align}
        \int d y_N P_N\left(y_1 y_2 \ldots y_N \mid \cdots\right)=P_{N-1}\left(y_1, \cdots y_{N-1}\right) \label{eq:reduction}
    \end{align}
}
\ex{}{
    \begin{align}
        \int P_2\left(y_1 y_2 \mid t_1 t_2\right) d y_2=P_1\left(y_1 \mid t_1\right)
    \end{align}
}
\subsection{Correlation functions}
Correlation functions are defined in the following ways:
\dfn{Correlation functions}{
    \begin{align}
        \ev{y(t)} &= \int y \cdot P(y,t) dy\\
        \left\langle y_1\left(t_1\right) y_2\left(t_2\right)\right\rangle&=\int y_1 y_2 p_2\left(y_1 y_2 \mid t_1 t_2\right)dy_1dy_2\\
        etc&\cdots
    \end{align}
}
\subsection{Stationary process}
A stationary process is defined when $P_1(y,t)$ is invariant under time shift, in other words, not time dependent. For such process, the correlation function $\ev{y(t)}$ has no time dependence and the second correlation $\left\langle y_1\left(t_1\right) y_2\left(t_2\right)\right\rangle$ will only depend on $\Delta t = t_1 - t_2$.
\subsection{Conditional probability}
For the case where $t_2>t_1$ it is very intuitive to think the probability $\left\langle y_1\left(t_1\right) y_2\left(t_2\right)\right\rangle$ can be written in terms of the product of $P_1(y_1|t_1)$ and some other function G, where G is the conditional probability of $y=y_2$ when $t=t_2$ given that $y=y_1$ when $t=t_1$.
\dfn{The propagator G}{
    \begin{align}
        \left.P_2\left(y_2 y_1 \mid t_2 t_1\right)=G(2 \mid 1) P_1\left(y_1 \mid t_2\right.\right) \label{eq:propagator}
    \end{align}
}
\subsection{Markov Process}
A Markov process is a stochastic process in which the probability of each event depends only on the state attained in the previous event, or we say it's "memoryless". In our case, the probability of all $P_i$ depends only on the single probability $P_1$ and our propagator G since the process has no "memory" of what happened before. Therefore if we want to calculate for example $P_4$, all we need is $P_1$ and then apply the propagator 3 more times.
\thm{Markov Process}{
    Any higher level probability $P_i$ can be constructed by using just the single probability $P_1$ and the propagator G.
}
\subsection{Evolution relation}
If we consider the setting mentioned in the propagator section, we can actually combine the reduction relation Eq.\eqref{eq:reduction} with the propagator Eq.\eqref{eq:propagator} to reach something called the evolution relation:
\begin{align}
    P_1\left(y_2 t_2\right)=\int G\left(y_2 y_1 \mid t_2 t_1\right) P_1\left(y_1 t_1\right) dy_1 \label{eq:evolution_relation}
\end{align}
\subsection{Kolmogorov-Chapman relation}
The last relation we're gonna talk about in this section is the Kolmogorov-Chapman relation. Now imagine we start with state 0 $(y_0,t_0)$, go through a transition state 1 $(y_1,t_1)$ at a given time $t=t_1$ and end up in state 2 $(y_2,t_2)$. The propagator between state 0 and state 2 can be expressed by:
\begin{align}
    G\left(y_2, y_0 \mid t_2, t_0\right)=\int G\left(y_2, y_1\mid t_2, t_1\right) G\left(y_1, y_0 \mid t_1, t_0\right) dy_1
\end{align}

%
%=======================================
%Lecture 3
%=======================================
%
\chapter{Lecture 3:The Poisson Process}
As we mentioned in the last chapter, a stationary Markov process is a process where 1. its higher probabilities $P_i$ can all be derived from the single probability $P_1$ and the propagator G 2. The probabilities are all invariant with respect to time shifts. Two stationary Markov processes are particularly important - the Poisson Process and the Wiener Process:
\begin{enumerate}
    \item Poisson Process:
    \begin{itemize}
        \item Independent steps
        \item Only forward steps
        \item Either go forward or not move after each step.
    \end{itemize}
    \item Wiener Process:
    \begin{itemize}
        \item Independent steps
        \item Can go both forward and backward
        \item Must go either forward or backwards after each step, must move!
    \end{itemize}
\end{enumerate}
\section{Poisson Process}
Let's give some examples so we can have a clearer understanding. Imagine shooting a target with a pistol, let's call every time a bullet is fired a "step". So the number of bullets that hit the target is a Poisson Process since after each step the number can only increase by one (go forward 1 step) or not change if we miss (not move).

Formulating the above example in maths, we have a status of the system $N(t)$ and a parameter $\nu$ which is the rate of a single forward step (N=n-1 to n) to happen (or else we don't move). The probability $P_+$ to make a step in time dt is $P_+ = \nu \cdot dt$. And $N(t)$ is our stochastic process. And the most common answers that we're looking for when using this model are: 1. How far forward would we go in time t? 2. How much time would it take for us to reach a certain point n?

\dfn{Poisson Process}{
    \begin{enumerate}
        \item Status of the system (integer): $N(t)$
        \item Rate of going forward: $\nu$
        \item Probability to go forward a step in time dt: $P_+ = \nu \cdot dt$
    \end{enumerate}
}

If the system is in the state $N(t) = n-1$ and we look into this single step going from (n-1) to (n), we can ask two questions: 1. What is the total probability $W(t)$ that the system makes this step after time t? 2. Equivalently, what is the "survival probability" $S(t)=1-W(t)$ that the system still remains in the state $N=n-1$ after time t? To obtain $S(t)$, we look at the relation between $S(t)$ and $S(t+dt)$:
\begin{align}
    S(t+d t)&=S(t) \cdot[1-\nu d t]\\
    \frac{d S}{d t}&=-v \cdot S \\
    \intertext{by using $S(t=0) = 1$ we get:}
    S(t)&=e^{-\nu t}
\end{align}
\dfn{Survival Probability}{
    $$S(t)=e^{-\nu t}$$
}
We can then get the average time it takes for the process to make this single step $\ev{t_1}$ by using $W(t)$ and the probability density $w(t)$:
\begin{align}
    \intertext{First define the probability density $w(t)$ of making the step:}
    w(t)=\frac{d W(t)}{d t}=-\frac{\partial S}{\partial t}=\nu e^{-\nu t}\\
    \intertext{Then the average time it takes to go forward this single step would be:}
    \left\langle t_1\right\rangle=\int t \cdot w(t) d t=\frac{1}{\nu}\\
    \intertext{and with a similar method, we can also get:}
    \sigma^2_t = \left\langle t_1^2\right\rangle-\left\langle t_1\right\rangle^2=\frac{1}{\nu^2}
\end{align}

\qs{Simulation excercise}{
    We are constantly flipping a biased coin and the stochastic process is the total number of heads obtained. The constant step time $\Delta t$ is the time it takes for each flip and the biased probability of flipping a head from the coin is $p_+$, we can express it in terms of the usual Poisson process rates:
    \begin{align}
        p_{+}=\nu{\Delta t} \quad \text { and } \quad p_0=1-\nu \Delta t
    \end{align}
    What's the probability $P(k,N)$ of having exactly k heads after these N steps (or after time $T=N\Delta t$)? (k is just like our position in a Poisson process, and $N = T/\Delta t$ is effectively a type of expression for total time T.)
}
We can see trivially that this is a binomial process without the need for simulation where:
\begin{align}
    p(k, N)=\frac{N !}{k !(N-b) !} \cdot p_{+}^k \cdot\left(1-p_{+}\right)^{N-k}
\end{align}
The interesting thing is that if you run a simulation with large enough N (small enough time step), p(k,N) reduces to:
\begin{align}
    p(k, \lambda)=\frac{\lambda^k}{k !} e^{-\lambda} 
\end{align}
Where $\lambda = Np_+ = \nu T$ is the expectation value of heads in the overall session. This is exactly the Poisson distribution! 
\dfn{Poisson distribution}{
    Poisson distribution is a discrete probability distribution that expresses the probability of a given number of events occurring in a fixed interval of time if these events occur with a known constant mean rate and independently of the time since the last event.
    \begin{align}
        p(k, \lambda)=\frac{\lambda^k}{k !} e^{-\lambda} \label{eq:Poisson_dist}
    \end{align}
    Where $\lambda = \nu T$ is the expected number of events in the given time interval.
}
\section{The Poisson distribution}
But how did we reach this result? Let's try to derive it using a standard Poisson process with external parameters position and time (n,t) and the rate $\nu$. First, let's start with the probability of being at position n at time t+dt:
\begin{align}
    P(n, t+d t)=P(n, t) \cdot[1-\nu d t]+P(n-1, t) \cdot \nu d t
\end{align}
The first term on the RHS represents the process where it was already at position n and carry on staying at the same spot after this small time interval, and the second term corresponds to it being at position n-1 and hopping forward into our desired state n in the small time interval. Using this relation, we can find: 
\begin{align}
    \frac{d P(n, t)}{d t} &= \left[P(n,t+dt)-P(n,t)\right]/dt\\
    &= \nu \cdot[P(n-1, t)-P(n, t)] \label{eq:master_equation_poisson}
\end{align}
In the square brackets of the second line, the first term and second terms can be considered as the "flux in" and "flux out" of the position n. This is often called the "Master Equation". Recall from the previous chapter the characteristic function $\phi_x(k)=\left\langle e^{i k x}\right\rangle$, we can define a "generating function" $g(k,t)$ using a similar logic:
\begin{align}
    g(k, t)&=\sum_{n=0}^{\infty} p(n, t) k^n \label{eq:g_definition} \\
    \intertext{If we differentiate it in respect of t:}
    \frac{\partial g(k, t)}{\partial t}&=\sum_{n=0}^{\infty} k^n \cdot v[p(n-1, t)-p(n, t)]\\
    \intertext{and reindex n into m-1 and regroup the terms}
    &=\sum_{m=0}^{\infty} v\left(k^{m+1}-k^m\right) P(m, t)\\
    &=v(k-1) \sum_{n=0}^{\infty} k^n P(n, t)\\
    \intertext{we can see the sum is the same as $g(k,t)$! So we have:}
    \frac{\partial g}{\partial t}&=v(k-1) \cdot g\\
    \intertext{By using the following initial conditions, we obtain the exponential form of g:}
    P(n, t=0)=\delta_{n, 0} &\Rightarrow g(t=0)=1\\
    g(k, t)&=e^{(k-1) v t}\\
    \intertext{Now expand the exponential and compare it with the definition of g (Eq.\refeq{eq:g_definition}):}
    g(k, t)&=e^{-\nu t} \sum_{n=0}^{\infty} \frac{1}{n !}(\nu t)^n \cdot k^n\\
    &=\sum_{n=0}^{\infty} p(n, t) k^n
    \intertext{We reach our conclusion:}
    P(n, t)&=\frac{1}{n !}(\nu t)^n e^{-\nu t}
\end{align}
Which is the same as Eq. \refeq{eq:Poisson_dist}.
We can then ask some simple questions about the expected values or probability of the process:
\ex{}{What is the expectation value of the occurring time of the 10th event?}
\sol
Considering each step is independent, the answer is simply:
\begin{align}
    \left\langle t_{10}\right\rangle=10\left\langle t_1\right\rangle=10/ v
\end{align}
\ex{}{What is the probability that the 10th event occurs after time t?}
\sol\\
There are two ways of doing this: 
1. Consider the probability $P\left(t_{10}>t\right)$:
Which we want to integrate the probability that the 10th event happens at exactly $t=t'$ over $t' = t \sim \infty$:
\begin{align}
    P\left(t_{10}>t\right)&=\int_t^{\infty} P(t_{10}=t')dt'\\
    \intertext{And we write this probability as a product of having exactly 9 events and having another one during the time interval dt':}
    &=\int_t^{\infty} \frac{\left(\nu t^{\prime}\right)^q}{q !} e^{-v t^{\prime}} \cdot v d t^{\prime}
\end{align}
2. The second way is much simpler, we just consider $P(n(t)<10)$, which is:
\begin{align}
    P(n(t)<10) = \sum_{j=0}^9 \frac{(\nu t)^j}{j !} e^{-\nu t}
\end{align}
\section{Evolution of the Master Equation}
Using the evolution relation (Eq. \refeq{eq:evolution_relation}), we can write out the evolution relation for any stationary Markov process distribution (not just Poisson): 
\begin{align}
    \intertext{(The integral has been replaced by a sum since m is discrete)}
    P(n, t+\Delta t)&=\sum_m G(n, t+\Delta t \mid m, t) \cdot P(m, t)\\
    \intertext{And if we subtract $P(n,t)$ from both sides:}
    \frac{\partial P(n, t)}{\partial t}&=\frac{1}{\Delta t}\left[\sum_m G(n, t+\Delta t m, t) P(m, t)
    -P(n, t) \cdot \sum_m G(m, t+ \Delta t \mid n, t)\right]\\
    \intertext{where:}
    \sum_m G(m, t+ \Delta t \mid n, t) = 1\\
    \intertext{we get:}
    &=\sum_m \frac{G\left(n, t+\Delta t \mid m, t\right)}{d t} P(m, t)-\sum_m \frac{G(m, t+\Delta t \mid u, t)}{d t} P(u, t)\\
    &=\sum_m\left[w_{n m} P(m, t)-w_{m n} P(n, t)\right]
\end{align}
Where $w_fi$ is the transition probabilities between initial state $\bmi$ to final state $\bmf$.
\begin{align}
    w_{fi}=\operatorname{limit~}_{d t \rightarrow 0} \frac{1}{d t} G(j, t+d t \mid i, t)
\end{align}
If we are considering the Poisson process, we need to imply the restrictions of $n > m$ and $n < m$ respectively on the two sums, but what we derived here is more general and did not include this restriction.

\chapter{Lecture 4: The Wiener process}
As the title suggests, we will be looking at the other stationary Markov process that we mentioned at the beginning of the last chapter, the Wiener process.

\section{The Wiener process}
So what is the Wiener process? Let's start with the definition of a random walk (Section \ref{section:random_walk}), where you have a random variable $\bmx$ (a single step) with probability density $P(\bmx)$ and a linked sequence $\bmy_N$, which can be converted into a time-dependent function $\bmy(t)$ with a stepping rate. We call this the Wiener process when the probability distribution of independent step $P(\bmx)$ is the Gaussian probability. And we usually use the expression $W(t)$ to represent a Wiener process (rather than $y(t)$).

\dfn{Wiener process}{A random walk $W(t)$ where the increment $\Delta W$ has the Gaussian probability of variance $\sigma^2 = \Delta t$
\begin{align}
    \Delta W&=W(t+\Delta t)-W(t)\\
    P(\Delta w)&=\frac{1}{\sqrt{2 \pi \Delta t}} \exp\left({-\frac{\Delta w^2}{2 \Delta t}}\right) \label{eq:wiener_step_prob}
\end{align}
}
\noindent And then there are a few important properties of the Wiener process:
\subsection{Characteristic function}
It is easy to check (Fourier Transform) that the characteristic function $\phi$ of $\Delta W$ is:
\thm{Wiener Characteristic Function}{
    \begin{align}
        \phi(k, t_0+\Delta t) & =\left\langle e^{i k (w_0+\Delta w)}\right\rangle_{P(\Delta w)} \\
        & =\exp\left(i k w_0-\frac{1}{2} k^2\left(\Delta t-t_0\right)\right)
    \end{align}
    where $w(t_0) = w_0$.
}
\subsection{Scaling}
If we speed up (or slow down) the rate of the process by a scaling factor $c$, this process can be linearly scaled into a Wiener-Process:
\thm{Scaling invariance}{
    \begin{align}
        V(t)=\frac{1}{\sqrt{c}} W(c t)
    \end{align}
    is a Wiener process. The scaling factor $1/\sqrt{c}$ came from the exponent in Eq. \eqref{eq:wiener_step_prob} since we need to keep the variance of $\Delta v$ as $\Delta t$. (If time flows faster and we're taking more steps per time, the steps must be smaller to keep the overall variance the same.)
}
\subsection{Time inversion}
This is a bit of a weird one to be interpreted physically.
\thm{Time inversion invariance}{
    \begin{align}
        V(t)=t \cdot W(1 / t)
    \end{align}
    is also a Wiener process.
}
\subsection{Time reversal}
If we reverse the time and relabel $W(t=A)$ to be the new origin, this is still a wiener process:
\thm{Time reversal invariance}{
    \begin{align}
        V(t)=W(A)-W(A-t)
    \end{align}
    is a Wiener process.
}
\subsection{Probability distribution} \label{section:wiener_probability}
Using the propagator $G = P(\Delta w)$ from the definition of a Wiener process:
\begin{align}
    &P(w+\Delta w, t+\Delta t)=\int_{-\infty}^{\infty} G(\Delta w, \Delta t) P(w, t) d w\\
    \intertext{And using the relation $\Delta w=w(t+\Delta t)-w(t)$, we can change the variables and change the integral $ d w=-d \Delta w $ (think $w(t+\Delta t)$ as a constant)}
    &=-\int_{\infty}^{-\infty} G(\Delta w, \Delta t) P(w(t+\Delta t)-\Delta w, t) d \Delta w\\
    \intertext{flipping the interval of integration back}
    &=\int_{-\infty}^{\infty} G(\Delta w, \Delta t) P(w(t+\Delta t)-\Delta w, t) d \Delta w\\
    \intertext{taking out the $-\Delta w$ term since it's $<< w(t)$}
    &=\int_{-\infty}^{\infty} G(\Delta w, \Delta t) P(w(t+\Delta t), t) d w w\\
    &-\int G(\Delta w, \Delta t) \Delta w \frac{\partial P}{\partial w} d \Delta w\\
    &+\frac{1}{2} \int G(\Delta w, \Delta t) \Delta w^2 \frac{\partial^2 P}{\partial w} d \Delta w
\end{align}
\begin{align}
    \intertext{The integral in the first line over G is 1 (P doesn't depend on $\Delta w$), due to normalisation over all possible $\Delta w$. The second line is 0 since it's a product of an even function G and odd function $\Delta w$:}
    P(w+\Delta w, t+\Delta t) - P(w(t+\Delta t), t) &= \frac{1}{2} \int G(\Delta w, \Delta t) \Delta w^2 d \Delta w \frac{\partial^2 p}{\partial w}\\
    \intertext{by using $\Delta w=w(t+\Delta t)-w(t)$ and the definition of variance:}
    \frac{\partial P(w, t)}{\partial t}&=\frac{1}{2} \frac{\sigma_{\Delta w}^2}{\Delta t} \cdot \frac{\partial^2 P\left(w, t\right)}{\partial w^2}\\
    \intertext{wrapping the terms up with D, we reach the diffusion equation:}
    \frac{\partial P\left(w, t\right)}{\partial t}&=D \frac{\partial^2 P\left(w, t\right)}{\partial w^2}\label{eq:wiener_diffusion}
\end{align}
From the derivation above, we conclude that the diffusion equation \eqref{eq:wiener_diffusion} is how $P(w,t)$ evolves over time. There is no universal solution to this equation since it depends on the initial boundary condition $P(w,t=0)$.
Although there is a special case where we start from a single point $w_0$, setting the boundary condition $P(w,t=0)$ to be $\delta(w=w_0)$. We get a Gaussian probability distribution:
\thm{Probabilty distribution of W(t)}{
    \begin{align}
        P(w,t) = w_0 + \frac{1}{\sqrt{2 \pi t}} e^{-x^2 /(2 t)} \label{eq:Wiener_prob}
    \end{align}
    with variance $\sigma_w^2 = t$.
}
It's easy to check that Eq. \eqref{eq:Wiener_prob} is a solution of the diffusion differential equation and converges to a delta function $P(w) = \delta(w-w_0)$ at t=0. (Plug it in yourself!) Also, by using the variance $\sigma_{\Delta w}^2$ of $\Delta t$ and Eq. \eqref{eq:random_walk_variance}, it's not hard to be convinced after time t ($N = t/\Delta t$ steps), the probability distribution of W(t) : $P(w,t)$ will still a Gaussian distribution if we start from a single point.

The equation for the global functions (such as the diffusion equation for the global probability distribution $P(w,t)$) are called "kinetic" or Macroscopic. And on a microscopic scale of $W(t)$, they're governed by "Stochastic differential equations", SDE.
\section{Stochastic differential equations}
Here's a fun little fact. With so many "Physics-inspired" algorithms/models nowadays, the solution of Brownian motion was actually "trading-inspired". In 1900, Louis Bachelier presented the method of stochastic analysis of stock and option markets in his PhD thesis "The theory of speculation". Then in 1905 Albert Einstein and Marian Smoluchowski brought the solution of Brownian motion to the attention of physicists and presented it as a way to indirectly confirm the existence of atoms and molecules. Later in 1911, Langevin proposed a more general approach to formulating and analysing SDEs. 

Let's start with something that we're all familiar with, the stochastic differential equation for Brownian Motion:
\begin{align}
    m \frac{d u}{d t}=-\gamma u+\xi(t)
\end{align}
where $u$ is the velocity of the particle and $\xi$ is a stochastic force. More generally, any SDE can be written like this:
\begin{align}
    \frac{d x}{d t}=\underbrace{F(x)}_{\text{drift term}}+\underbrace{\sigma(x) \Delta W(t)}_{\text{diffusion term}}
\end{align}
where W is the normalised Wiener process, and $\sigma(x)$ is the amplitude which may depend on x. The reason why the second term is called the diffusion term is that if we have only the second term, the differential equation can be written in the diffusion equation form with diffusion equation $D = \frac{1}{2} \sigma^2$.

Mathematically (mathematician uses this notation because they don't trust the physicists with maths), the same SDE above can be written as:
\begin{align}
    d x_t=\mu(x, t) d t+\omega(x, t) d w_t \label{eq:sde_math_notation}
\end{align}
since we have a wiener term $d w_t$, if the steps $d t$ is small enough, we expect $dx_t$ to be Gaussian as well (have gaussian probability distribution).
\section{Example: Geometric Brownian Motion}
The difference between geometric and typical Brownian motion is that for each step $\Delta t$, the value of the motion is multiplied by the step $x$ rather than added. Just like a geometric vs an arithmetic series, hence the "geometric" in the name.

\dfn{Geometric Brownian Motion}{
    A stochastic process such that:
    \begin{align}
        d S_t=\mu \cdot S_t \cdot d t+\sigma \cdot S_t d w_t \label{eq:GBM}
    \end{align}
}
which is also known as the "percentage drift" or the "percentage volatility".

To solve this we rearrange the equation above into:
\begin{align}
    \frac{d S_t}{S_t}=\mu \cdot d t+c \cdot d w_t
    \intertext{which you will very intuitively write into:}
    \cancelto{\text{Wrong!}}{d \ln S_t = d\left(\mu t+\sigma w_t\right)}
\end{align}
But this second line above is actually WRONG!!! $\int \sigma d w_t$ is not actually $\sigma w_t$! The problem stems from the cheeky term $\int d w_t$. Although in our notation we wrote the infinitesimal interval $d w_t$ in the integral, the function $w_t$ is not actually a smooth continuous differentiable function (The mathematicians lied to us rip). The solution that we deal with this has a name called "Itoh Calculus".
\section{Itoh Lemma}
In this section, it's all mathematician BS, so we used some big words to blend in. So the Itoh lemma was formed to solve the following question:
\qs{Itoh Lemma}{
    If we have a stochastic process $x(t)$ with SDE:
    \begin{align}
        d x_t=\mu d t+\sigma d w_t
    \end{align}
    and a fucntion $f(x)$ that depends on x. What is the SDE for f?
}
\noindent First we start with the definition of df:
\begin{align}
    d f&=f(x+d x)-f(x)\\
    \intertext{which the terms may all have explicit time dependence. We Taylor expand them:}
    &=\frac{\partial f}{\partial t} d t+\frac{\partial f}{\partial x} d x+\frac{1}{2} \frac{\partial^2 f}{\partial x^2} d x^2+\cdots \cdots
    \intertext{then using $d x_t=\mu(x, t) d t+\omega(x, t) d w_t$ from Eq\eqref{eq:sde_math_notation} and only keeping terms linear in dt:}
    \intertext{(Note that $\left\langle d w_t^2\right\rangle=d t$ for fast steps with small time interval)}
    &=\frac{\partial f}{\partial t} d t+\frac{\partial f}{\partial x}(\mu \delta t+\sigma d w)+\frac{1}{2} \frac{\partial^2 f}{\partial x^2}\left(\mu^2 \cancelto{0}{dt^2} +2 \mu \sigma \cancelto{0}{d t d w_t} + \sigma^2 d w_t^2 \right)
    \intertext{Now:}
    d f&=\left(\frac{\partial f}{\partial t}+\mu \frac{\partial f}{\partial x}+\frac{1}{2} \sigma^2 \frac{\partial^2 f}{\partial x^2}\right) \cdot d t + \underbrace{\sigma \frac{\partial f}{\partial x} \cdot d w_t}_{\text{diffusion term}}
\end{align}
\mlenma{Itoh Lemma}{
    If we have a stochastic process $x(t)$ with SDE:
    \begin{align}
        d x_t=\mu d t+\sigma d w_t
    \end{align}
    and a fucntion $f(x)$ that depends on x. The SDE for f is:
    \begin{align}
        d f&=\left(\frac{\partial f}{\partial t}+\mu \frac{\partial f}{\partial x}+\frac{1}{2} \sigma^2 \frac{\partial^2 f}{\partial x^2}\right) \cdot d t + \sigma \frac{\partial f}{\partial x} \cdot d w_t \label{lemma:Itoh}
    \end{align}
}
Now applying the same analysis to Geometric Brownian Motion Eq.\eqref{eq:GBM} and consider the function $f(S) = \ln S_t$:
\begin{align}
d(\ln S) & =\frac{\partial f}{\partial S} d S+\frac{1}{2} \frac{\partial^2 f}{\partial S^2} d S^2 \\
& =\frac{d S}{S}-\frac{1}{2 S^2} d S^2 \\
& =\frac{d S}{S}-\frac{1}{2 S^2}\left(\mu^2 S^2 \cancelto{0}{d t^2}+2 \mu \sigma S^2 \cancelto{0}{d t d w} +\sigma^2 S^2 d w^2\right) \\
& =\frac{d S}{S}-\frac{\sigma^2}{2} d t
\intertext{which gives:}
S&=S_0 \exp \left(\left(u-\frac{\sigma^2}{2}\right)t + \sigma w_t \right)
\end{align}
\dfn{Solution of Geometric Brownian Motion}{
    \begin{align}
    S(t)=S_0 \exp \left(\left(u-\frac{\sigma^2}{2}\right)t + \sigma w_t \right)
    \end{align}
}
\noindent From this we can see two interesting things:
\begin{enumerate}
    \item Since $d w_t$ is a small step Wiener process, we have a diffusive growth $e^{\sigma w_t}$
    \item If we solved the differential equation without the diffusion term we would've reached the solution:
    \begin{align}
        d S=\mu s d t \rightarrow S=S_0 e^{\mu t}
        \intertext{But instead we have a shift in the deterministic drift term, giving us a lower growth rate:}
        S \propto \exp \left(\mu-\frac{\sigma^2}{2}\right) t
    \end{align}
\end{enumerate}

\noindent Try using the code on the \href{https://en.wikipedia.org/wiki/Geometric_Brownian_motion}{GBM Wikipedia page} to produce GBM graphs in Python!

\chapter{Lecture 5}
In this lecture, we will be using the two things we introduced in the last lecture, Etoh's lemma and Geometric Brownian Motion, to study the Black-Scholes equation, which won the Nobel prize for economics in 1997. So what is the Black-Scholes equation and how is it useful? It is a mathematical analysis of dynamics and prediction of option prices in volatile markets that are stochastic. The term "option" might not be familiar to some readers, in simple terms, the B-S equation gives investment managers a tool to allocate their risk and cash. For example, buying more stocks is allocating more risk and less cash. 

Interestingly, there are theories that suggest that the 1987 financial crisis was caused by a group of traders that conspired to punish the early adopters of the B-S analysis. Even more interestingly, one of the main causes of the 2008 financial crisis is actually too much trust in the B-S analysis and incorrect use of it (Since they didn't pick the ASM option in Lent like you obviously lol). 

\section{Black-Scholes Equation}
So first we use a stochastic variable $S(t)$ to present the value of a given stock, which is governed by the SDE of Geometric Brownian Motion (GBM):
\begin{align}
    d S=\mu S d t+\sigma S d w \label{eq:StockSDE}
\end{align}
since in stocks we usually describe the growth in percentage growth and not linear growth. An "Option" is a contract when you (the seller) agree to sell me (the buyer) a certain stock $\mathcal{S}$, at a future time t, at the current price if the future price satisfies certain conditions (For example reach a trigger price $E$). So you see the seller hopes the stock to depreciate and then the opposite for the buyer. You might think, why would the seller agree to a such weird contract? They already have the stock in hand and can sell them at any time that they want! The only reason that a seller will be interested in such a contract is if the buyer (me) pays a small extra fee for this. We denote this fee as another stochastic variable $V(s, t)$, which depends on the value of the stock $S$ and time $t$. A "Portfolio" $\Pi$ is a combination of assets (cash, stocks, options etc.) that I currently have:
\begin{align}
    \Pi=-V\left(s_t\right)+\alpha S
\end{align}
where the $-V$ came from the amount that you have already paid for the options contract, and $\alpha S$ from selling a portion $\alpha$ of that same stock at the same time to "hedge" aka decrease risk exposure (Just like the hedge in "Hedge fund"). In continuous trading, we have small increments of time, therefore:
\begin{align}
    \Delta \Pi=-\Delta V(s)+\alpha \Delta S
\end{align}
Now, we can use the Itoh Lemma \refeq{lemma:Itoh}:
\begin{align}
    d V(s)&=\left(\frac{\partial V}{\partial t}+\frac{\partial V}{\partial s} d s+\frac{1}{2} \frac{\partial^2 V}{\partial s^2} d s^2\right)
    \intertext{And subbing in:}
    d s&=\mu s d t+\sigma s d w
    \intertext{We get:}
    d V(s)&=\left(\frac{\partial v}{\partial t}+\mu s \frac{\partial v}{\partial s}+\frac{1}{2} \sigma^2 s^2 \frac{\partial^2 v}{\partial s^2}\right) d t +\sigma s \frac{\partial V}{\partial s} d W
    \intertext{Then substitute $dV$ and $dS$ into $d\Pi$:}
    d \Pi=-\frac{\partial v}{\partial t} d t-\mu s \frac{\partial v}{\partial s} d t&-\frac{1}{2} \sigma^2 s^2 \frac{\partial^2 v}{\partial s^2} d t +\alpha \mu s d t-\underbrace{\sigma s \frac{\partial v}{\partial s} d W+\alpha \sigma s d W}_{\text{stochastic part}}
\end{align}
With our stochastic description of $d\Pi$, the key step of reaching the BS equation is to choose the factor $\alpha$ to be $\partial V / \partial S$ so the volatility terms above cancel out and we have no volatility in $d\Pi$. Then, we make a decision on what we want to achieve for $d\Pi$ (The goal of our investments), a steady geometric growth:
\begin{align}
    d \Pi=r \cdot \Pi d t
\end{align}
Getting us the relation with rate $r$:
\begin{align}
    r \cdot \overbrace{(\alpha S-V)}^{\Pi} d t &=\left(-\frac{\partial V}{\partial t}-\cancel{\mu s \frac{\partial V}{\partial s}}-\frac{1}{2} \sigma^2 s^2 \frac{\partial^2 V}{\partial S^2}+\ \cancel{\alpha \mu s}\right) d t\\
\end{align}
Finally we have the B-S equation:
\dfn{Black-Scholes Equation}{
    \begin{align}
        \frac{\partial V(s, t)}{\partial t}&+\frac{1}{2} \sigma^2 s^2 \frac{\partial^2 V}{\partial s^2}=r\left(V-s \frac{\partial V}{\partial s}\right)
    \end{align}
}
It allows us to solve for $V(s,t)$ for any given $r$ and $\sigma$. The lack of dependence on $\mu$ makes it even more powerful since if we look back to our SDE Eq.\refeq{eq:StockSDE} for $S(t)$, it is $\mu$ that makes the growth of each stock different and the $dW$ term is just geometric stochastic term that represents the market volatility and does not relate to the growth.

What about r? What are the restrictions on this risk-free geometric growth? The "desired legislation" should have this rate of risk-free growth fixed (limited). We will not go into too much detail about the impact of $r$ in the overall economy since we're physicists not econ students. In reality, we use the rate of US Treasury Bonds $r_0$ (effectively the interest rate you get by lending money to the US government) since they are such a global superpower and the capitalists believe lending money to them is risk-free lol.
\section{A simple case}
Let's consider the case where $r=0$ and see how the Black-Scholes equation is useful if we were a hedge fund manager back in the 1980s skrskr:
\begin{align}
    \frac{\partial V}{\partial t}+\frac{\sigma^2}{2} S^2 \frac{\partial^2 V}{\partial S^2}=0
\end{align}
Later in the course, you will see that this is actually the "super diffusion" equation (Another great naming from the physicists ofc) since the diffusion constant $D = \frac{\sigma^2}{2} S^2$ grows as $S^2$, the effective position (non-linear diffusion).

Using this equation, we can solve for the fair value of the contract $V$ at the current time and buy all options that are underpriced and sell all the overpriced ones.

(Note: There's another interesting question to ask: Do we really know the value of volatility $\sigma$? To this day, the measurement or modelling of $\sigma$ is still a very competitive field between hedge funds and a lot of different analyses are still being proposed.)

With all that waffling above, how do we actually solve for $V(s,t)$ using this equation?
Using the current price($t=0$) of a stock $S$ and the trigger price$E$ of the stock at the end of the contract $(t=T)$, we define:
\begin{align}
    x&=\ln S / E\\
    S&=E e^x\\
    \tau &= T - t
    \intertext{re-express $V$ into:}
    V&\left(E e^x, T-\tau\right)=Z(x, \tau)
    \intertext{we get:}
    \frac{\partial z}{\partial \tau}-\frac{\sigma^2}{2} \frac{\partial^2 z}{\partial x^2}&+\left(\frac{\sigma^2}{2}-r\right) \frac{\partial z}{\partial x}+r =0
\end{align}
Which is a homogeneous differential equation! In order to solve this, there's a beautiful solution by introducing a new variable $u$:
\begin{align}
    u(x, \tau)&=z(x, \tau) \cdot e^{\alpha x+\beta \tau}
    \intertext{plugging it into the PDE above:}
    \frac{\partial u}{\partial \tau}-\frac{\sigma^2}{2} \frac{\partial^2 u}{\partial x^2}&+A(\alpha, \beta) \cdot \frac{\partial u}{\partial x}+\underbrace{B(\alpha, \beta)} \cdot u=0
    \intertext{choose an $\alpha$ and $\beta$ that yields $A=B=0$: (try it yourself!)}
    \alpha&=r / \sigma^2-1 / 2 \\
    \beta&=r / 2+\sigma^2 / 8+r^2 / 2\sigma^2
    \intertext{and all we have left is:}
    \frac{\partial u}{\partial \tau}-&\frac{\sigma^2}{2} \frac{\partial^2 u}{\partial x^2} = 0
\end{align}
Amazing right? The last step is to simply solve this by using Green's function and its initial condition:
\begin{align}
    u(x, \tau)=\int \underbrace{\frac{1}{\sqrt{2 \pi \sigma^2 \tau}} \exp\left({-\frac{(x-w)^2}{2 \sigma^2 \tau}}\right)}_{\text{Green's function}} \cdot \underbrace{u(w, 0)}_{\text{initial condition}} d w
\end{align}
and hence we can backroll and find $Z$, and $V(s,t)$.

\chapter{Lecture 6: Ornstein-Uhlenbeck process}
After all that discussion about financial maths, in this lecture let's go back to physical systems and talk about the Ornstein-Uhlenbeck process. 
\section{Ornstein-Uhlenbeck process}
Once again, let's start with the most general form of an SDE:
\begin{align}
    d x_t=\mu(x, t) d t+\sigma(x, t) d w
\end{align}
The O-U process is when $\mu$ and $\sigma$ are chosen to be:
\dfn{Ornstein-Uhlenbeck process SDE}{
    \begin{align}
        d x_t=\Theta\cdot\left(x_0-x\right) d t+\sigma d w \label{eq:OU_SDE}
    \end{align}
}
where $\Theta, x_0, \sigma$ are constants. This might seem like something completely new but actually, we have seen this before! Let's look at this equation:
\begin{align}
    m \dot{v}&=-\gamma v+\sqrt{2 k_B T \cdot \gamma} \xi(t) \label{eq:free_diffusion}
    \intertext{this is the Brownian motion equation in the Part II TSP course, also known as the free diffusion equation. If we divide both sides by m and times by $dt$:}
    d v&=-\frac{\gamma}{m} v \cdot d t+\sqrt{\frac{2 k_B T \cdot \gamma}{m}} d W \label{eq:brownian_OU_SDE}
\end{align}
In comparison to Eq \refeq{eq:OU_SDE}, this is the same equation with $x =v$, $\Theta = \gamma / m$, $x_0 = 0$, $\sigma = \sqrt{\frac{2 k_B T \cdot \gamma}{m}}$, and $dW = \xi(t)$. 

Or similarly, the diffusion equation in a spring potential:
\begin{align}
    \gamma \dot{x}&=-k\left(x-x_0\right)+\sqrt{2 k_b T \cdot \gamma} \xi(t)
    \intertext{rearrange:}
    d x&=-\frac{k}{\gamma}\left(x-x_0\right) d t+\sqrt{\frac{2 k_B T}{\gamma}} d w
\end{align}
where we can see this is just another Ornstein-Uhlenbeck SDE with a different choice of constants. So why is the O-U important? Seems like just another SDE with a niche form. The reason lies in the linear term $\Theta\cdot\left(x_0-x\right)$. Most physical processes near equilibrium can be approximated with a linear restoring force, or a parabolic potential (think about Taylor expansion). So the O-U process is what describes the dynamic of a stochastic system near equilibrium.

Before going into more details about O-U, let's revise some basic mechanics:
\begin{align}
    \intertext{relation between position and velocity:}
    x(t)&=\int_0^t v(s) d s\\
    \intertext{using the product of this and taking the ensemble average:}
    \left\langle x^2(t)\right\rangle&=\int_0^t d s_1 \int_0^t d s_2\left\langle v\left(s_1\right) v\left(s_2\right)\right\rangle
    \intertext{taking the time derivative, we should have 2 identical integrals since $s1,s2$ is symmetrical under exchange:}
    \frac{d}{d t}\left\langle x^2(t)\right\rangle&=2 \int_0^t d s\langle v(t) v(s)\rangle
    \intertext{Using the relation we got above and comparing it to the diffusion equation $\left\langle x^2\right\rangle=2 D t$, we see that:}
    D&=\int_0^t\langle v(t) v(s)\rangle \quad \text{(1D case)}\\
    \text{or} \quad D&=\frac{1}{N}\int_0^t\langle v(t) v(s)\rangle \quad \text{(ND case)}
    \intertext{in the end we shift the time by $\tilde{s}=t-s$ so it looks neater:}
    D&=\int_0^t d \tilde{s}\langle v(\tilde{s}) v(0)\rangle \label{eq:neat_D}
\end{align}
Let's go back to the free diffusion equation \refeq{eq:free_diffusion}. If we times both sides by $v(0)$ and take the average over the whole ensemble:
\begin{align}
    m \frac{d}{d t}\langle v(t) \cdot v(0)\rangle&=-\gamma\langle v(t) v(0)\rangle + C \cancelto{0}{\langle \xi(t) \cdot v(0)\rangle}\\
    &=-\gamma\langle v(t) v(0)\rangle
    \intertext{The last term cancels out due to the stochastic nature of $\xi$, so: }
    \langle v(t) v(0)\rangle&=\langle v(0)^2\rangle e^{-\frac{\gamma}{m} t} \label{eq:v_self_correlation}
    \intertext{then subbing it back into Eq \refeq{eq:neat_D}:}
    D=\left\langle v_0^2\right\rangle \int_0^t d s \space\space e^{-\frac{\gamma}{m} s} &=\left\langle\nu_0^2\right\rangle \frac{m}{\gamma}\left(1-e^{-\frac{\gamma}{m} t}\right)
\end{align}
We have obtained a time-dependent value of $D$ instead of the usual constant form. How do we physically interpret this exponential decay in time? The exponential term in the self-correlation of $\nu$ in Eq. \refeq{eq:v_self_correlation} can be interpreted as a "memory" with relaxation time scale $m/\gamma$. If our time $t$ is much greater than this "time of velocity relaxation", which gives the system enough time to forget its initial conditions and reach its equilibrium, we can obtain a constant form of D:
\begin{align}
   D \approx \frac{m}{\gamma}\left\langle v_0^2\right\rangle=\frac{k \pi}{\gamma} \quad \text{(we used the 2D case where }m\left\langle v_0^2\right\rangle = k_B T) 
\end{align}

\dfn{Green-Kubo formula}{
    For a time that's much longer than the relaxation time, we define the usual diffusion constant that we use to be:
    \begin{align}
         D=\int_0^{\infty}\langle v(t) v(0)\rangle d t
    \end{align}
}
\section{O-U process with multiple variablese}
By choosing the equilibrium point $x_0 = 0$ we have the usual single variable O-U SDE:
\begin{align}
    d x&=-\theta x d t+\sigma d w
    \intertext{Now if we want to make it multi-variable:}
    d x_i&=-\theta_{i k} x_k d t+\sigma_{i k} d w_k\\ \label{eq:OU_mv_SDE}
    \text{or} \quad \frac{d}{d t} x_i&=-\theta_{i k} x_k+C_{i k} \xi_k
\end{align}
The reason for the matrices $\theta_{i k},\sigma_{i k}$ is so variables can be correlated to each other so we don't just boringly have one independent ODE for each variable. To solve this, we convolve the initial condition with Green's function:
\begin{align}
    x_i(t)=\int_0^t \underbrace{e^{e^{-\theta_{i k}(t-s)}}}_{G(t-s)} \cdot \sigma_{k e} \xi_l^{(s)} d s \label{eq:OU_mv_solution}
\end{align}
If you are not quite convinced by this, you can check it by differentiation and it gives you the same as Eq.\refeq{eq:OU_mv_SDE}.

Now we construct a matrix $M_{ik}$ to represent the correlation functions:
\begin{align}
    M_{i k}&=\left\langle x_i(t) x_k(t)\right\rangle
    \intertext{subbing in Eq. \refeq{eq:OU_mv_solution}:}
    M_{i k}=\int_0^t d s_1 \int_0^t d s_2 \ \  &e^{-\theta_{i m}\left(t-s_1\right)} e^{-\theta_{k p}\left(t-s_2\right)}\cdot \sigma_{m l}\sigma_{p q}\cdot\langle \xi_l\left(s_1\right) \xi_q\left(s_2\right)\rangle
    \intertext{since Wiener processes are not related to one another, the average term can be written into:}
    \left\langle\xi_e\left(s_1\right) \xi_q\left(s_2\right)\right\rangle &= \delta_{q e} \delta\left(s_1-s_2\right)
\end{align}
therefore:
\begin{align}
    M_{ik} &= \int_0^t d s e^{-\theta_{i m}(t-s)} \sigma_{m l} \cdot \sigma_{p l} e^{-\theta_{k p}(t-s)}\\
    \doubleunderline{M}&=\int_0^t d s e^{-\doubleunderline{\theta}(t-s)} \doubleunderline{\sigma} \cdot \doubleunderline{\sigma}^\top \cdot e^{\left(-\doubleunderline{\theta}^\top t-s\right)}
    \intertext{taking t to infinity (to be in the equilibrium state) and shifting time $(t-s) \rightarrow \tilde{t}$ to make it look nicer:}
    \doubleunderline{M}&=\int_0^\infty d s \exp \left(-\doubleunderline{\theta}\tilde{t}\right) \doubleunderline{\sigma} \cdot \doubleunderline{\sigma}^\top \cdot \exp \left(-\doubleunderline{\theta}^\top \tilde{t}\right)
\end{align}
\begin{example}{Single variable case}
    for the 1 variable case, the equation above becomes:
    \begin{align}
        M=\left\langle x^2\right\rangle=\int_0^{\infty} d t e^{-2 \theta t} \cdot \sigma^2=\frac{\sigma^2}{2 \theta}
    \end{align}
    which gives the value of $\left\langle x^2\right\rangle$ in equilibrium state. 
    If we use it on the Eq.\refeq{eq:brownian_OU_SDE}, we get:
    \begin{align}
        \left\langle v^2\right\rangle=\frac{2 k_B T \gamma}{2 \gamma m} = \frac{k T}{m}
    \end{align}
\end{example}

Let's now construct another matrix that's related to the fluctuation-dissipation relationship(we love matrices rip):
\begin{align}
    \doubleunderline{\theta} \cdot \doubleunderline{M}+\underline{\underline{M}} \cdot \doubleunderline{\theta}^{\top}
\end{align}
remember, neither $\theta$ nor $\sigma$ need to be symmetric (I hate these double underlines):
\begin{align}
    \doubleunderline{\theta} \underline{\underline{M}}+\doubleunderline{M} \doubleunderline{\theta^{\top}}&=\int_0^{\infty} d t\left[\doubleunderline{\theta} \cdot e^{-\doubleunderline{\theta} t} \doubleunderline{\sigma} \doubleunderline{\sigma^{\top}} e^{-\doubleunderline{\theta}^{\top} t}+e^{\doubleunderline{\theta} t} \doubleunderline{\sigma \sigma^\top} \cdot e^{-\doubleunderline{\theta}^{\top} t} \cdot \doubleunderline{\theta}^{\top}\right]
    \intertext{noticing that the square bracket can be written into a time derivative:}
    &=-\int_0^{\infty} d t \frac{d}{dt}\left[ e^{-\doubleunderline{\theta} t} \doubleunderline{\sigma} \doubleunderline{\sigma^{\top}} e^{-\doubleunderline{\theta}^{\top} t}\right]
    \intertext{and the square bracket goes to 0 for t towards $\infty$ so the integral becomes:}
    &= \doubleunderline{\sigma}\doubleunderline{\sigma^\top}
\end{align}
In the end, this gives us:
\begin{align}
    \theta_{i k}\left\langle x_k x_l\right\rangle+\left\langle x_i x_k\right\rangle \theta_{e_k}=\sigma_{i k} \sigma_{l k}
\end{align}
So why do we care about this weirdly-looking matrix? It gives us a direct way of solving for all correlators in equilibrium between variables $\ev{x_i x_j}$ using the constant matrices $\sigma$ and $\theta$.\chapter{Lecture 6: Ornstein-Uhlenbeck process}
After all that discussion about financial maths, in this lecture let's go back to physical systems and talk about the Ornstein-Uhlenbeck process. 
\section{Ornstein-Uhlenbeck process}
Once again, let's start wit the most general form of an SDE:
\begin{align}
    d x_t=\mu(x, t) d t+\sigma(x, t) d w
\end{align}
The O-U process is when $\mu$ and $\sigma$ are chosen to be:
\dfn{Ornstein-Uhlenbeck process SDE}{
    \begin{align}
        d x_t=\Theta\cdot\left(x_0-x\right) d t+\sigma d w \label{eq:OU_SDE}
    \end{align}
}
where $\Theta, x_0, \sigma$ are constants. This might seems like something completely new but actually, we have seen this before! Let's look at this equation:
\begin{align}
    m \dot{v}&=-\gamma v+\sqrt{2 k_B T \cdot \gamma} \xi(t) \label{eq:free_diffusion}
    \intertext{this is the brownian motion equation in the Part II TSP course, also known as the free diffusion equation. If we divide both sides by m and times by $dt$:}
    d v&=-\frac{\gamma}{m} v \cdot d t+\sqrt{\frac{2 k_B T \cdot \gamma}{m}} d W \label{eq:brownian_OU_SDE}
\end{align}
In comparison to Eq \refeq{eq:OU_SDE}, this is the same equation with $x =v$, $\Theta = \gamma / m$, $x_0 = 0$, $\sigma = \sqrt{\frac{2 k_B T \cdot \gamma}{m}}$, and $dW = \xi(t)$. 

Or similarly, the diffusion equation in a spring potential:
\begin{align}
    \gamma \dot{x}&=-k\left(x-x_0\right)+\sqrt{2 k_b T \cdot \gamma} \xi(t)
    \intertext{rearrange:}
    d x&=-\frac{k}{\gamma}\left(x-x_0\right) d t+\sqrt{\frac{2 k_B T}{\gamma}} d w
\end{align}
where we can see this is just another Ornstein-Uhlenbeck SDE with a different choice of the constants. So why is the O-U important? Seems like just another SDE with a niche form? The reason lies in the linear term $\Theta\cdot\left(x_0-x\right)$. Most physical processes near equilibrium can be approximated with a linear restoring force, or a parabolic potential (think about Taylor-expansion). So the O-U process is what describes the dynamic of a stochastic system near equilibrium.

Before going into more details about O-U, let's revise some basic mechanics:
\begin{align}
    \intertext{relation between position and velocity:}
    x(t)&=\int_0^t v(s) d s\\
    \intertext{using the product of this and taking the ensemble average:}
    \left\langle x^2(t)\right\rangle&=\int_0^t d s_1 \int_0^t d s_2\left\langle v\left(s_1\right) v\left(s_2\right)\right\rangle
    \intertext{taking the time derivative, we should have 2 identical integrals since $s1,s2$ is symmetrical under exchange:}
    \frac{d}{d t}\left\langle x^2(t)\right\rangle&=2 \int_0^t d s\langle v(t) v(s)\rangle
    \intertext{Using the relation we got above and comparing it to the diffusion equation $\left\langle x^2\right\rangle=2 D t$, we see that:}
    D&=\int_0^t\langle v(t) v(s)\rangle \quad \text{(1D case)}\\
    \text{or} \quad D&=\frac{1}{N}\int_0^t\langle v(t) v(s)\rangle \quad \text{(ND case)}
    \intertext{in the end we shift the time by $\tilde{s}=t-s$ so it looks neater:}
    D&=\int_0^t d \tilde{s}\langle v(\tilde{s}) v(0)\rangle \label{eq:neat_D}
\end{align}
Let's go back to the free diffusion equation \refeq{eq:free_diffusion}. If we times both sides by $v(0)$ and take the average over the whole ensemble:
\begin{align}
    m \frac{d}{d t}\langle v(t) \cdot v(0)\rangle&=-\gamma\langle v(t) v(0)\rangle + C \cancelto{0}{\langle \xi(t) \cdot v(0)\rangle}\\
    &=-\gamma\langle v(t) v(0)\rangle
    \intertext{The last term canecls out due to the stochastic nature of $\xi$, so: }
    \langle v(t) v(0)\rangle&=\langle v(0)^2\rangle e^{-\frac{\gamma}{m} t} \label{eq:v_self_correlation}
    \intertext{then subbing it back into Eq \refeq{eq:neat_D}:}
    D=\left\langle v_0^2\right\rangle \int_0^t d s \space\space e^{-\frac{\gamma}{m} s} &=\left\langle\nu_0^2\right\rangle \frac{m}{\gamma}\left(1-e^{-\frac{\gamma}{m} t}\right)
\end{align}
We have obtained a time dependent value of $D$ instead of the usual constant form. How do we physically interpret this exponential decay in time? The exponential term in the self correlation of $\nu$ in Eq. \refeq{eq:v_self_correlation} can be interpreted as a "memory" with relaxation time scale $m/\gamma$. If our time $t$ is much greater than this "time of velocity relaxation", which the give the system enough time to forget its initial conditions and reach its equilibrium, we can obtain a contant form of D:
\begin{align}
   D \approx \frac{m}{\gamma}\left\langle v_0^2\right\rangle=\frac{k \pi}{\gamma} \quad \text{(we used the 2D case where }m\left\langle v_0^2\right\rangle = k_B T) 
\end{align}

\dfn{Green-Kubo formula}{
    For a time that's much longer than the relaxation time, we define the usual diffusion constant that we use to be:
    \begin{align}
         D=\int_0^{\infty}\langle v(t) v(0)\rangle d t
    \end{align}
}
\section{O-U process with multiple variablese}
By choosing the equilibrium point $x_0 = 0$ we have the usual single variable O-U SDE:
\begin{align}
    d x&=-\theta x d t+\sigma d w
    \intertext{Now if we want to make it multi-variable:}
    d x_i&=-\theta_{i k} x_k d t+\sigma_{i k} d w_k\\ \label{eq:OU_mv_SDE}
    \text{or} \quad \frac{d}{d t} x_i&=-\theta_{i k} x_k+C_{i k} \xi_k
\end{align}
The reason of the matrices $\theta_{i k},\sigma_{i k}$ is so variables can be correlated to each other so we don't just boringly have one independent ODEs for each variables. To solve this, we convolve the initial condition with the Green's function:
\begin{align}
    x_i(t)=\int_0^t \underbrace{e^{e^{-\theta_{i k}(t-s)}}}_{G(t-s)} \cdot \sigma_{k e} \xi_l^{(s)} d s \label{eq:OU_mv_solution}
\end{align}
If you are not quite convinced by this, you can check it by differentiation and it gives you the same as Eq.\refeq{eq:OU_mv_SDE}.

Now we construct a matrix $M_{ik}$ to represent the correlation functions:
\begin{align}
    M_{i k}&=\left\langle x_i(t) x_k(t)\right\rangle
    \intertext{subbing in Eq. \refeq{eq:OU_mv_solution}:}
    M_{i k}=\int_0^t d s_1 \int_0^t d s_2 \ \  &e^{-\theta_{i m}\left(t-s_1\right)} e^{-\theta_{k p}\left(t-s_2\right)}\cdot \sigma_{m l}\sigma_{p q}\cdot\langle \xi_l\left(s_1\right) \xi_q\left(s_2\right)\rangle
    \intertext{since Wiener processes are not related to one another, the average term can be written into:}
    \left\langle\xi_e\left(s_1\right) \xi_q\left(s_2\right)\right\rangle &= \delta_{q e} \delta\left(s_1-s_2\right)
\end{align}
therefore:
\begin{align}
    M_{ik} &= \int_0^t d s e^{-\theta_{i m}(t-s)} \sigma_{m l} \cdot \sigma_{p l} e^{-\theta_{k p}(t-s)}\\
    \doubleunderline{M}&=\int_0^t d s e^{-\doubleunderline{\theta}(t-s)} \doubleunderline{\sigma} \cdot \doubleunderline{\sigma}^\top \cdot e^{\left(-\doubleunderline{\theta}^\top t-s\right)}
    \intertext{taking t to infinity (to be in the equilibrium state) and shifting time $(t-s) \rightarrow \tilde{t}$ to make it look nicer:}
    \doubleunderline{M}&=\int_0^\infty d s \exp \left(-\doubleunderline{\theta}\tilde{t}\right) \doubleunderline{\sigma} \cdot \doubleunderline{\sigma}^\top \cdot \exp \left(-\doubleunderline{\theta}^\top \tilde{t}\right)
\end{align}
\begin{example}{Single variable case}
    for the 1 variable case, the equation above becomes:
    \begin{align}
        M=\left\langle x^2\right\rangle=\int_0^{\infty} d t e^{-2 \theta t} \cdot \sigma^2=\frac{\sigma^2}{2 \theta}
    \end{align}
    which gives the value of $\left\langle x^2\right\rangle$ in equilibrium state. 
    If we use it on the Eq.\refeq{eq:brownian_OU_SDE}, we get:
    \begin{align}
        \left\langle v^2\right\rangle=\frac{2 k_B T \gamma}{2 \gamma m} = \frac{k T}{m}
    \end{align}
\end{example}

Let's now construct another matrix that's related to the fluctuation-dissapation relationship(we love matrices rip):
\begin{align}
    \doubleunderline{\theta} \cdot \doubleunderline{M}+\underline{\underline{M}} \cdot \doubleunderline{\theta}^{\top}
\end{align}
remember, neither $\theta$ nor $\sigma$ need to be symmetric (I hate these double underlines):
\begin{align}
    \doubleunderline{\theta} \underline{\underline{M}}+\doubleunderline{M} \doubleunderline{\theta^{\top}}&=\int_0^{\infty} d t\left[\doubleunderline{\theta} \cdot e^{-\doubleunderline{\theta} t} \doubleunderline{\sigma} \doubleunderline{\sigma^{\top}} e^{-\doubleunderline{\theta}^{\top} t}+e^{\doubleunderline{\theta} t} \doubleunderline{\sigma \sigma^\top} \cdot e^{-\doubleunderline{\theta}^{\top} t} \cdot \doubleunderline{\theta}^{\top}\right]
    \intertext{noticing that the square bracket can be written into a time derivative:}
    &=-\int_0^{\infty} d t \frac{d}{dt}\left[ e^{-\doubleunderline{\theta} t} \doubleunderline{\sigma} \doubleunderline{\sigma^{\top}} e^{-\doubleunderline{\theta}^{\top} t}\right]
    \intertext{and the square bracket goes to 0 for t towards $\infty$ so the integral becomes:}
    &= \doubleunderline{\sigma}\doubleunderline{\sigma^\top}
\end{align}
In the end, this gives us:
\begin{align}
    \theta_{i k}\left\langle x_k x_l\right\rangle+\left\langle x_i x_k\right\rangle \theta_{e_k}=\sigma_{i k} \sigma_{l k}
\end{align}
So why do we care about this weirdly looking matrix? It gives us a direct way of solving for all correlator in equilibrium between variables $\ev{x_i x_j}$ using the constant matrices $\sigma$ and $\theta$.




\end{document}